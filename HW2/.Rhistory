knitr::opts_chunk$set(fig.height=5, fig.width=11, warning = F)
# constants for homework assignments
hw_num <- 2
hw_due_date <- "Oct 10, 2018"
# Use rnorm() to generate a predictor X of length n=100, and a noise vector of length n = 100.
rnorm(100,0,2)
# Use rnorm() to generate a predictor X of length n=100, and a noise vector of length n=100.
rnorm(100)
y <- rnorm.noise(100)
# Use rnorm() to generate a predictor X of length n=100, and a noise vector of length n=100.
x <- rnorm(100)
y <- rnorm(100)
# Use rnorm() to generate a predictor X of length n=100, and a noise vector of length n=100.
x <- rnorm(100)
y <- rnorm(100)
noise <- rnorm(100)
delete(y)
remove(y)
# Generate a response vector Y of length n = 100 according to the model
y <- 1 + 2*x + 3*x^2 + 4*x^3 + noise
knitr::opts_chunk$set(echo = TRUE, results = "hide")
knitr::opts_chunk$set(fig.height=7, fig.width=10, warning = F)
#options(scipen = 1, digits = 4)
if(!require('pacman')) {
install.packages('pacman')
}
pacman::p_load(ISLR, leaps, car, tidyverse, GGally, reshape2)
help(regsubsets)
help(Hitters)
help(regsubsets)
help(Hitters)
dim(Hitters)
names(Hitters)
str(Hitters)  #summary(Hitters) a good way to check abnormality
sum(is.na(Hitters)) # this may not work if the missing is not coded as "NA"
# Use the regsubsets() function to perform best subset selection
regsubsets(y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 + x^7 + x^8 + x^9 + x^(10),data = x, nvmax = 4)
# Use the regsubsets() function to perform best subset selection
regsubsets(y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 + x^7 + x^8 + x^9 + x^10,data = x, nvmax = 4)
str(y)
y
x
typeof(x)
# Use rnorm() to generate a predictor X of length n = 100, and a noise vector of length n = 100
x <- data.frame(rnorm(100))
# Use rnorm() to generate a predictor X of length n = 100, and a noise vector of length n = 100
x <- rnorm(100)
# Use rnorm() to generate a predictor X of length n = 100, and a noise vector of length n = 100
x <- rnorm(100)
noise <- rnorm(100)
# Generate a response vector Y of length n = 100 according to the model
y <- 1 + 2*x + 3*x^2 + 4*x^3 + noise
# Use the regsubsets() function to perform best subset selection
new_data <- data.frame(x,noise,y)
regsubsets(y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 + x^7 + x^8 + x^9 + x^10,data = new_data, nvmax = 4)
new_data
regsubsets(y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 + x^7 + x^8 + x^9 + x^10,data = new_data, nvmax = 1)
regsubsets(y ~ x,data = new_data, nvmax = 1)
new_subset <- regsubsets(y ~ x + x^2 + x^3 + x^4 + x^5 + x^6 + x^7 + x^8 + x^9 + x^10,data = new_data, nvmax = 1)
new_subset <- regsubsets(y ~ .,data = new_data, nvmax = 1)
new_subset
# Use rnorm() to generate a predictor X of length n = 100, and a noise vector of length n = 100
x <- rnorm(100)
noise <- rnorm(100)
# Generate a response vector Y of length n = 100 according to the model
y <- 1 + 2*x + 3*x^2 + 4*x^3 + noise
# Use the regsubsets() function to perform best subset selection
x2 <- x^2
x3 <- x^3
x4 <- x^4
x5 <- x^5
x6 <- x^6
x7 <- x^7
x8 <- x^8
x9 <- x^9
x10 <- x^10
new_data <- data.frame(x,x2,x3,x4,x5,x6,x7,x8,x9,x10,noise,y)
new_subset <- regsubsets(y ~ .,data = new_data, nvmax = 1)
new_subset <- regsubsets(y ~ .,data = new_data, nvmax = 4)
new_subset
names(new_subset)
summary(new_subset)
names(new_subset)
summary <- summary(new_subset)
summary
names(summary)
summary$which
data.frame(variables=(1:length(summary$rsq)), r_squared=summary$rsq)
remove(summary)
data.frame(variables = (1:length(new_summary$rsq)),
r_squared = new_summary$rsq,
rss = new_summary$rss,
bic = new_summary$bic,
cp = new_summary$cp)
new_summary <- summary(new_subset)
new_summary$which
data.frame(variables=(1:length(new_summary$rsq)), r_squared=new_summary$rsq)
# What is the best model?
data.frame(variables = (1:length(new_summary$rsq)),
r_squared = new_summary$rsq,
rss = new_summary$rss,
bic = new_summary$bic,
cp = new_summary$cp)
par(mfrow=c(3,1), mar=c(2.5,4,0.5,1), mgp=c(1.5,0.5,0))     # Compare different criteria
plot(f.e$cp, xlab="Number of predictors",
ylab="cp", col="red", type="p", pch=16)
# Comparing the plots for cp, bic, and r2
plot(new_summary$cp, xlab="Number of predictors",
ylab="cp", col="red", type="p", pch=16)
plot(new_summary$bic, xlab="Number of predictors",
ylab="bic", col="blue", type="p", pch=16)
plot(new_summary$adjr2, xlab="Number of predictors",
ylab="adjr2", col="green", type="p", pch=16)
new_subset <- regsubsets(y ~ .,data = new_data, nvmax = 11)
new_summary <- summary(new_subset)
new_summary$which
data.frame(variables=(1:length(new_summary$rsq)), r_squared=new_summary$rsq)
# What is the best model?
data.frame(variables = (1:length(new_summary$rsq)),
r_squared = new_summary$rsq,
rss = new_summary$rss,
bic = new_summary$bic,
cp = new_summary$cp)
# Comparing the plots for cp, bic, and r2
plot(new_summary$cp, xlab="Number of predictors",
ylab="cp", col="red", type="p", pch=16)
plot(new_summary$bic, xlab="Number of predictors",
ylab="bic", col="blue", type="p", pch=16)
plot(new_summary$adjr2, xlab="Number of predictors",
ylab="adjr2", col="green", type="p", pch=16)
plot(new_summary$bic, xlab="Number of predictors",
ylab="bic", col="blue", type="p", pch=16)
# Find the optimal model size for Cp
opt.size <- which.min(new_summary$cp)
opt.size
# What is the best model?
data.frame(variables = (1:length(new_summary$rsq)),
r_squared = new_summary$rsq,
rss = new_summary$rss,
bic = new_summary$bic,
cp = new_summary$cp)
new_summary <- summary(new_subset)
new_summary$which
# Use the regsubsets() function to perform best subset selection
new_data <- data.frame(x,x2,x3,x4,x5,x6,x7,x8,x9,x10,noise,y)
new_subset <- regsubsets(y ~ x+x2+x3+x4+x5+x6+x7+x8+x9+x10,data = new_data, nvmax = 10)
new_summary <- summary(new_subset)
new_summary$which
data.frame(variables=(1:length(new_summary$rsq)), r_squared=new_summary$rsq)
# What is the best model obtained?
data.frame(variables = (1:length(new_summary$rsq)),
r_squared = new_summary$rsq,
rss = new_summary$rss,
bic = new_summary$bic,
cp = new_summary$cp)
# What is the best model obtained?
data.frame(variables = (1:length(new_summary$rsq)),
r_squared = new_summary$rsq,
rss = new_summary$rss,
bic = new_summary$bic,
cp = new_summary$cp)
# Comparing the plots for Cp, bic, and r2
plot(new_summary$cp, xlab="Number of predictors",
ylab="cp", col="red", type="p", pch=16)
plot(new_summary$bic, xlab="Number of predictors",
ylab="bic", col="blue", type="p", pch=16)
plot(new_summary$adjr2, xlab="Number of predictors",
ylab="adjr2", col="green", type="p", pch=16)
# Find the optimal model size for Cp
opt.size <- which.min(new_summary$cp)
opt.size
# Find the optimal model size for Cp
opt.size <- which.min(new_summary$cp)
opt.size
# Find the optimal model size for bic
opt.size <- which.min(new_summary$bic)
opt.size
# Find the optimal model size for r2
opt.size <- which.min(new_summary$rsq)
opt.size
# Find the optimal model size for Cp
opt.size <- which.min(new_summary$cp)
opt.size
# Use rnorm() to generate a predictor X of length n = 100, and a noise vector of length n = 100
x <- rnorm(100)
noise <- rnorm(100)
# Generate a response vector Y of length n = 100 according to the model
y <- 1 + 2*x + 3*x^2 + 4*x^3 + noise
# Create the predictors x^2 through x^10
x2 <- x^2
x3 <- x^3
x4 <- x^4
x6 <- x^6
x8 <- x^8
x9 <- x^9
x10 <- x^10
# Use the regsubsets() function to perform best subset selection
new_data <- data.frame(x,x2,x3,x4,x5,x6,x7,x8,x9,x10,noise,y)
new_subset <- regsubsets(y ~ x+x2+x3+x4+x5+x6+x7+x8+x9+x10,data = new_data, nvmax = 10)
new_summary <- summary(new_subset)
new_summary$which
new_summary$which
data.frame(variables=(1:length(new_summary$rsq)), r_squared=new_summary$rsq)
data.frame(variables=(1:length(new_summary$rsq)), r_squared=new_summary$rsq)
# What is the best model obtained?
data.frame(variables = (1:length(new_summary$rsq)),
r_squared = new_summary$rsq,
rss = new_summary$rss,
bic = new_summary$bic,
cp = new_summary$cp)
# Comparing the plots for Cp, bic, and r2
plot(new_summary$cp, xlab="Number of predictors",
ylab="cp", col="red", type="p", pch=16)
plot(new_summary$bic, xlab="Number of predictors",
ylab="bic", col="blue", type="p", pch=16)
plot(new_summary$adjr2, xlab="Number of predictors",
ylab="adjr2", col="green", type="p", pch=16)
# Find the optimal model size for Cp
opt.size <- which.min(new_summary$cp)
opt.size
# Find the optimal model size for bic
opt.size <- which.min(new_summary$bic)
opt.size
# Find the optimal model size for r2
opt.size <- which.min(new_summary$rsq)
opt.size
# Report the coefficients of the best model obtained
coef(new_summary, 6)
# Report the coefficients of the best model obtained
coef(new_summary, 4)
# Report the coefficients of the best model obtained
summary(new_summary)
model <- lm(new_summary)
model <- lm(y ~ x + x2 + x3, new_summary)
new_summary
new_summary$coefficients
new_summary$coefficients
model <- lm(y ~ x + x2 + x3, new_summary)
model <- lm(y ~ x + x2 + x3, new_subset)
new_subset$coefficients
coef(new_summary, 4)
coef(new_summary)
new_subset$coefficients
new_subset
names(new_subset)
data.frame(variables=(1:length(new_summary$rsq)), r_squared=new_summary$rsq, print_coef=new_summary$coefficients)
# Report the coefficients of the best model obtained
coef(new_summary, 3)
fit.exh <- regsubsets(LogSalary ~., data2, nvmax=25, method="exhaustive")
data2 <- read.csv(file = "Hitters_comp", row.names = "X")
# Report the coefficients of the best model obtained
coef(new_subset, 3)
# Repeat using forward selection
forward <- regsubsets(y ~ x+x2+x3+x4+x5+x6+x7+x8+x9+x10,data = new_data, nvmax = 10, method = "forward")
forward
forward_sum <- summary(forward)
forward_sum
plot(forward_sum$rsq, ylab="rsq", col="red", type="p", pch=16,
xlab="Forward Selection")
lines(new_summary$rsq, ylab="rsq", col="blue", type="p", pch=16,
xlab="All Subset Selection")
plot(forward_sum$rsq, ylab="rsq", col="red", type="p", pch=16,
xlab="Forward Selection")
# Find the optimal model size for forward selection
opt.size <- which.min(forward_sum$rsq)
opt.size
# Repeat using backward selection
backward <- regsubsets(y ~ x+x2+x3+x4+x5+x6+x7+x8+x9+x10,data = new_data, nvmax = 10, method = "backward")
backward_sum <- summary(backward)
backward_sum
plot(backward_sum$rsq, ylab="rsq", col="red", type="p", pch=16,
xlab="Forward Selection")
# Find the optimal model size for forward selection
opt.size <- which.min(backward_sum$rsq)
opt.size
backward_sum
plot(backward_sum$rsq, ylab="rsq", col="red", type="p", pch=16,
xlab="Forward Selection")
# Report the coefficients for forward selection
coef(forward, 3)
# Repeat using backward selection
backward <- regsubsets(y ~ x+x2+x3+x4+x5+x6+x7+x8+x9+x10,data = new_data, nvmax = 10, method = "backward")
backward_sum <- summary(backward)
backward_sum
plot(backward_sum$rsq, ylab="rsq", col="red", type="p", pch=16,
xlab="Backward Selection")
# Find the optimal model size for backward selection
opt.size <- which.min(backward_sum$rsq)
opt.size
# Report the coefficients for backward selection
coef(backward, 3)
knitr::opts_chunk$set(fig.height=5, fig.width=11, warning = F)
# constants for homework assignments
hw_num <- 2
hw_due_date <- "Oct 10, 2018"
auto <- ISLR::Auto
#Taking a look at the data
dim(auto)
str(auto)
#Taking a look at the data
dim(auto)
install.packages("glmnet")
